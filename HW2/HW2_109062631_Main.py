#   Homework 2: Convolutional Autoencoder - Module
#    
#   Date:        2020/11/06
#   CourseID:    10910COM526000
#   Course:      Deep Learning (Graduated)
#   
#   Writer_ID:   109062631
#   Writer_Name: Wang, Chuan-Chun
#   Environment: 
#      Software: Python 3.8.5 on 64-bit Windows 10 Pro (2004)
#      Hardware: Intel i7-10510U, 16GB DDR4 non-ECC ram, and no discrete GPU
from HW2_109062631_Module import *

########## Main function ##########
if __name__ == "__main__":
    # Read .npy files
    data_ndarray, label_ndarray = readNPY()
    data_tensor, label_tensor = torch.Tensor(data_ndarray), torch.Tensor(label_ndarray)
    
    # Create PyTorch DataLoader
    torch_dataset = torch.utils.data.TensorDataset(data_tensor, label_tensor)
    torch_loader  = torch.utils.data.DataLoader(torch_dataset, batch_size=CONST.batch_size(), num_workers=0)
    
    mode = str(input('Do you want to load pre-trained model to prevent wasting time? (Y/N): ')).upper()
    if mode == 'N':
        # Prepare some initial steps
        hw_device = have_CUDA()
        conv_AE   = convAutoEncdr()
        optimizer = torch.optim.Adam(conv_AE.parameters(), lr=CONST.learning_rate())
        conv_AE.to(hw_device)
        conv_AE.train() # Enable self.training to True
        
        print("Start training a model.")
        for epoch in range(CONST.epoch_num()):
            cur_loss = 0.0
            
            for inputs, _ in torch_loader:
                # VAE re-construction
                inputs = inputs.to(hw_device)
                outputs = conv_AE(inputs)
                
                # Calculate re-construction error
                temp_loss = lossFunc(outputs, inputs)
                
                # Backward propagation
                optimizer.zero_grad() # Set all the gradients to zero before backward propragation
                temp_loss.backward()
                
                # Performs a single optimization step.
                optimizer.step()
                cur_loss += temp_loss.item() * inputs.size(0)
                  
            cur_loss = cur_loss / len(torch_loader)
            print('Epoch: {}\tTraining loss: {:.4f}'.format(epoch+1, cur_loss))
        
        model_file_name = 'CAE.pk'
        torch.save(conv_AE, model_file_name)
        print("\nPre-trained model have been save as 'CAE.pk'.")
        print("You can use it next time to save your time.\n")
    elif mode == 'Y':
        hw_device = have_CUDA()
        if os.path.exists('CAE_optimal.pk'):
            print("Load model from CAE_optimal.pk")
            conv_AE = torch.load('CAE_optimal.pk', map_location=torch.device(hw_device))
        elif os.path.exists('CAE.pk'):
            print("Load model from CAE.pk")
            conv_AE = torch.load('CAE.pk', map_location=torch.device(hw_device))
        else:
            print("\nCannot find pre-trained model 'CAE_optimal.pk'.")
            print("Please re-run python script to produce it.\n")
    else:
        print("Please enter 'Y' or 'N'.")
        exit()
    
    # Save additional 6405 samples generated by Gaussian noise to .npy
    conv_AE.train()
    normal_recon = conv_AE(data_tensor)
    
    conv_AE.eval()
    noise_recon1 = conv_AE(data_tensor)
    noise_recon2 = conv_AE(data_tensor)
    noise_recon3 = conv_AE(data_tensor)
    noise_recon4 = conv_AE(data_tensor)
    noise_recon5 = conv_AE(data_tensor)
    
    print("Processing data, please wait for several minutes.")
    # Set maximum value channel to 1
    for index in range(noise_recon1.shape[0]):
        noise_recon1[index, :, :, :] = setMaxCHToOne(noise_recon1[index, :, :, :])
        noise_recon2[index, :, :, :] = setMaxCHToOne(noise_recon2[index, :, :, :])
        noise_recon3[index, :, :, :] = setMaxCHToOne(noise_recon3[index, :, :, :])
        noise_recon4[index, :, :, :] = setMaxCHToOne(noise_recon4[index, :, :, :])
        noise_recon5[index, :, :, :] = setMaxCHToOne(noise_recon5[index, :, :, :])
    
    # Find one tensor index for each class of 9-label
    class_index = []
    for each_class in range(9):
        for index in range(label_tensor.shape[0]):
            if label_tensor[index, 0].item() == each_class:
                class_index.append(index)
                break
    
    for each_class in class_index:
        class_num = int(label_tensor[each_class, 0].item())
        printImage(data_tensor[each_class, :, :, :], save_file_name='label'+str(class_num)+'_origin.png')
        printImage(normal_recon[each_class, :, :, :], save_file_name='label'+str(class_num)+'_recons.png')    
        printImage(noise_recon1[each_class, :, :, :], save_file_name='label'+str(class_num)+'_noise1.png')
        printImage(noise_recon2[each_class, :, :, :], save_file_name='label'+str(class_num)+'_noise2.png')
        printImage(noise_recon3[each_class, :, :, :], save_file_name='label'+str(class_num)+'_noise3.png')
        printImage(noise_recon4[each_class, :, :, :], save_file_name='label'+str(class_num)+'_noise4.png')
        printImage(noise_recon5[each_class, :, :, :], save_file_name='label'+str(class_num)+'_noise5.png')
    
    # Packaging to numpy ndarray and dumping to .npy
    gen_data_ndarray = noise_recon1.detach().numpy()
    gen_data_ndarray = numpy.append(gen_data_ndarray, noise_recon2.detach().numpy(), axis=0)
    gen_data_ndarray = numpy.append(gen_data_ndarray, noise_recon3.detach().numpy(), axis=0)
    gen_data_ndarray = numpy.append(gen_data_ndarray, noise_recon4.detach().numpy(), axis=0)
    gen_data_ndarray = numpy.append(gen_data_ndarray, noise_recon5.detach().numpy(), axis=0)
    gen_data_ndarray = numpy.rollaxis(gen_data_ndarray, 1, 4)
    with open('gen_data.npy', 'wb') as f:
        numpy.save(f, gen_data_ndarray)
    
    gen_label_ndarray = label_tensor.numpy()
    gen_label_ndarray = numpy.append(gen_label_ndarray, label_tensor.numpy(), axis=0)
    gen_label_ndarray = numpy.append(gen_label_ndarray, label_tensor.numpy(), axis=0)
    gen_label_ndarray = numpy.append(gen_label_ndarray, label_tensor.numpy(), axis=0)
    gen_label_ndarray = numpy.append(gen_label_ndarray, label_tensor.numpy(), axis=0)
    with open('gen_label.npy', 'wb') as f:
        numpy.save(f, gen_label_ndarray)
    

########## Other Notes ##########
# data_tensor  : (# of inputs) x (image width) x (image height) x (3-channel)
# label_tensor : (# of inputs) x (label)
# 3-channel : boundary T/F, normal T/F, defect T/F
# label is nine-class
# Deep comparison two object: print(pickle.dumps(obj1) == pickle.dumps(obj2))
# Over sampling to each classes:
#+-------+----------------------+
#| Class | # of Instances Added |
#+-------+----------------------+
#| 0     | 314                  |
#+-------+----------------------+
#| 1     | 403                  |
#+-------+----------------------+
#| 2     | 108                  |
#+-------+----------------------+
#| 3     | 373                  |
#+-------+----------------------+
#| 4     | 107                  |
#+-------+----------------------+
#| 5     | 388                  |
#+-------+----------------------+
#| 6     | 330                  |
#+-------+----------------------+
#| 7     | 332                  |
#+-------+----------------------+
#| 8     | 1                    |
#+-------+----------------------+
'''
# Print re-construction result
for _ in range(3):
    rand_index = random.randint(0, data_tensor.shape[0]-1)
    
    conv_AE.train()
    normal_recon = conv_AE(data_tensor)
    
    conv_AE.eval()
    noise_recon1 = conv_AE(data_tensor)
    print(noise_recon1)
    noise_recon2 = conv_AE(data_tensor)
    noise_recon3 = conv_AE(data_tensor)
    noise_recon4 = conv_AE(data_tensor)
    noise_recon5 = conv_AE(data_tensor)
    
    printImage(data_tensor[rand_index, :, :, :])
    printImage(normal_recon[rand_index, :, :, :])
    printImage(noise_recon1[rand_index, :, :, :])
    printImage(noise_recon2[rand_index, :, :, :])
    printImage(noise_recon3[rand_index, :, :, :])
    printImage(noise_recon4[rand_index, :, :, :])
    printImage(noise_recon5[rand_index, :, :, :])
'''
# Over Sampling
#data_resampled, label_resampled = RandomOverSampler().fit_resample(data_ndarray, label_ndarray)